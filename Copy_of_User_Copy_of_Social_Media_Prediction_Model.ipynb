{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wtcEMU2Ny6XNa_3qGvWRnzLy1_6_PGgD",
      "authorship_tag": "ABX9TyNq4+g3Ncd7u5/ecJn17/l3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvdraper04/nvdraper04.github.io/blob/main/Copy_of_User_Copy_of_Social_Media_Prediction_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instructions:**\n",
        "**Here is the link to the data needed for the model:** https://docs.google.com/spreadsheets/d/1t9lz4LYOMkNrJvGVRj-JNHD7XotbuiOdUpVUh4PoDEI/edit?usp=sharing\n",
        "\n",
        "\n",
        "After the the Google Sheet is added to your Google Drive, you can hit the \"Run all\" button above and it will run all the code for you. At the end of the run it should take you directly to the chunk of code where you can make a social media prediction."
      ],
      "metadata": {
        "id": "-o-had5kXN88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing packages and Cleaning Data"
      ],
      "metadata": {
        "id": "Zho415ffZkSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!pip install pandas scikit-learn streamlit\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# Authenticate to Google\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Get the credentials and create an authorized client.\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Open the spreadsheet by its title or URL\n",
        "spreadsheet = gc.open('User Copy of Combined Social Media Data')\n",
        "\n",
        "# Select the first worksheet\n",
        "worksheet = spreadsheet.sheet1\n",
        "\n",
        "# Get all values from the worksheet as a list of lists\n",
        "data = worksheet.get_all_values()\n",
        "\n",
        "# Convert the list of lists to a pandas DataFrame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "#display(df.tail())"
      ],
      "metadata": {
        "id": "5dpvHKYigda0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Identify columns with missing values\n",
        "#print(df.isnull().sum())\n",
        "\n",
        "# Convert specified columns to numeric, coercing errors to NaN\n",
        "numerical_cols_to_convert = ['Duration (sec)', 'Impressions', 'Reach', 'Plays', 'Saves', 'Likes', 'Shares', 'Comments']\n",
        "for col in numerical_cols_to_convert:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Fill missing numerical values with the mean\n",
        "numerical_cols_with_missing = ['Duration (sec)', 'Impressions', 'Reach', 'Plays', 'Saves', 'Likes', 'Shares', 'Comments']\n",
        "for col in numerical_cols_with_missing:\n",
        "    df[col] = df[col].fillna(df[col].mean())\n",
        "\n",
        "# Fill missing 'Description' values with an empty string\n",
        "df['Description'] = df['Description'].fillna(\"\")\n",
        "\n",
        "# Fill missing 'Genres' and 'Content_type' with a placeholder\n",
        "df['Genres'] = df['Genres'].fillna('Unknown')\n",
        "df['Content_type'] = df['Content_type'].fillna('Unknown')\n",
        "\n",
        "\n",
        "# Convert 'Publish_Date' and 'Time' to datetime objects\n",
        "df[\"Publish_Date\"] = pd.to_datetime(df[\"Publish_Date\"].astype(str), errors='coerce')\n",
        "df[\"Time\"] = pd.to_datetime(df[\"Time\"].astype(str), errors='coerce')\n",
        "\n",
        "\n",
        "df['Year'] = df['Publish_Date'].dt.year\n",
        "df['Month'] = df['Publish_Date'].dt.month\n",
        "df['Day_of_Week'] = df['Publish_Date'].dt.dayofweek # Monday=0, Sunday=6\n",
        "df['Hour'] = pd.to_datetime(df['Time'].astype(str)).dt.hour\n",
        "#df['Publish_Date'] = datetime.datetime.strptime(df['Publish_Date'], \"%Y-%m-%d %H:%M:%S\")\n",
        "#print(df['Publish_Date'].hour)\n",
        "\n",
        "#print(df['Hour'])\n",
        "#print(df[\"Day_of_Week\"])\n",
        "\n",
        "# Print the dtypes of the numerical columns after conversion\n",
        "#print(df[numerical_cols_to_convert].dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vljimEBVPHj6",
        "outputId": "6a162403-a9af-409e-cd4a-6c7ff8083cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-255013841.py:24: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[\"Time\"] = pd.to_datetime(df[\"Time\"].astype(str), errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "#categorical_features = [\"Platform\", \"Post type\", \"Genres\", \"Content_type\", \"Hour\", \"Month\", \"Day_of_Week\"] # with genre and content\n",
        "categorical_features = [\"Platform\", \"Post type\", \"Hour\", \"Month\", \"Day_of_Week\"] # without genre and content\n",
        "encoder = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
        "one_hot_features = encoder.fit_transform(df[categorical_features])\n",
        "one_hot_names = encoder.get_feature_names_out()\n",
        "#print(\"Type of one_hot_columns is:\",type(one_hot_features))"
      ],
      "metadata": {
        "id": "AJVIPAOOUS2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_df = pd.DataFrame.sparse.from_spmatrix(one_hot_features)\n",
        "one_hot_df.columns = one_hot_names # Now we can see the actual meaning of the one-hot feature in the DataFrame\n",
        "#one_hot_df.head()"
      ],
      "metadata": {
        "id": "z7MidJ3BtwAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import scipy\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "df['clean_caption'] = df['Description'].apply(clean_text)\n",
        "\n",
        "# Apply TF-IDF vectorization\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = tfidf.fit_transform(df['Description'])\n",
        "\n",
        "#vectorizer = CountVectorizer()   # limit features if needed\n",
        "#X_text = vectorizer.transform(df['clean_caption'])\n",
        "\n",
        "#numerical_feature_names = [\"Impressions\", \"Reach\", \"Shares\", \"Plays\", \"Comments\", \"Saves\", \"Year\", \"Month\", \"Day_of_Week\", \"Hour\"] # Make Year, Month, and day categorial\n",
        "numerical_feature_names = [\"Duration (sec)\",\"Reach\", \"Shares\", \"Plays\", \"Comments\", \"Saves\"] # Make Year, Month, and day categorial\n",
        "numerical_features = df[numerical_feature_names]\n",
        "\n",
        "# Print dtypes to identify the problematic column\n",
        "print(numerical_features.dtypes)\n",
        "\n",
        "features = scipy.sparse.hstack((numerical_features, one_hot_features),format='csr')\n",
        "features_without_numerical = scipy.sparse.csr_matrix(one_hot_features)\n",
        "features_with_text = scipy.sparse.hstack((features, tfidf_matrix),format='csr')\n",
        "features_with_text_without_numerical = scipy.sparse.hstack((features_without_numerical, tfidf_matrix),format='csr')\n",
        "#print(feature_with_text)\n",
        "all_feature_names = np.hstack((numerical_feature_names,one_hot_names))\n",
        "#target_column = ['Likes']\n",
        "#target = df[target_column].values\n",
        "target = df['Likes']\n",
        "print(target)\n",
        "\n",
        "# Perform train and test split of data\n",
        "rand_seed = 51 # For other models we will use the same random seed, so that we're always using the same train-test split\n",
        "features_train, features_test, target_train, target_test = train_test_split(\n",
        "    features, target, test_size=0.2, random_state=rand_seed) # 80 / 20 split\n",
        "\n",
        "features_train_with_text, features_test_with_text, target_train, target_test = train_test_split(\n",
        "    features_with_text, target, test_size=0.2, random_state=rand_seed)\n",
        "\n",
        "features_train_with_text_without_numerical, features_test_with_text_without_numerical, target_train, target_test = train_test_split(\n",
        "    features_with_text_without_numerical, target, test_size=0.2, random_state=rand_seed)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1NXqsot-YCVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1d100e-85d8-4267-ef12-e0ad3e30c25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration (sec)      int64\n",
            "Reach             float64\n",
            "Shares              int64\n",
            "Plays             float64\n",
            "Comments            int64\n",
            "Saves             float64\n",
            "dtype: object\n",
            "0        2\n",
            "1        6\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "        ..\n",
            "1297     2\n",
            "1298     5\n",
            "1299     2\n",
            "1300     0\n",
            "1301    23\n",
            "Name: Likes, Length: 1302, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Accuracy Check"
      ],
      "metadata": {
        "id": "qVxuQbmhZ-0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "ridge_fit_without_text = linear_model.RidgeCV(cv=5)\n",
        "ridge_fit_without_text.fit(features_train, target_train)\n",
        "ridge_fit_with_text = linear_model.RidgeCV(cv=5)\n",
        "ridge_fit_with_text.fit(features_train_with_text, target_train)\n",
        "ridge_fit_with_text_without_numerical = linear_model.RidgeCV(cv=5)\n",
        "ridge_fit_with_text_without_numerical.fit(features_train_with_text_without_numerical, target_train)\n",
        "\n",
        "ridge_test_score_no_text = ridge_fit_without_text.score(features_test,target_test)\n",
        "ridge_test_score_with_text = ridge_fit_with_text.score(features_test_with_text,target_test)\n",
        "ridge_test_score_with_text_without_numerical = ridge_fit_with_text_without_numerical.score(features_test_with_text_without_numerical,target_test)\n",
        "print(\"Test score for Regression WITHOUT text features:\", ridge_test_score_no_text)\n",
        "print(\"Test score for Regression WITH text features:\", ridge_test_score_with_text)\n",
        "print(\"Test score for Regression WITH text features and WITHOUT numerical features:\", ridge_test_score_with_text_without_numerical)"
      ],
      "metadata": {
        "id": "Fraex0oGektW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a4cec9-2b29-44df-c546-00e0a9348e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score for Regression WITHOUT text features: 0.8328140839043826\n",
            "Test score for Regression WITH text features: 0.8323800926500413\n",
            "Test score for Regression WITH text features and WITHOUT numerical features: -0.5188041471387692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions for inputing data to make a prediction:\n",
        "\n",
        "When this block of code is ran, the user will be asked the following questions one at a time:\n",
        "\n",
        "\n",
        "*   What will be the duration of the post (in seconds)? If the post is an image, enter 0.\n",
        "*   Which platform will the post be on?\n",
        "*   What type of post will it be? IG reel or IG image?\n",
        "*   What hour of the day will the post be published (0-23)?\n",
        "*   What month will the post be published (1-12)?\n",
        "*   What day of the week will the post be published (0 for Monday, 6 for Sunday)?\n",
        "*   Please provide a caption / description for the post:\n",
        "\n",
        "After an answer is typed, press the enter key on your keyboard to move on to the next question. At the end, you should be provided an estimate on how many likes your post may recieve. You will also be asked if you want to make another prediction. For this question, either type in yes or no then press enter. If you type in no but want to make another prediction you will have to run this block of code again or press the Run all button again.\n",
        "\n",
        "## Note:\n",
        "*   For the platform question, the only platform the model currently takes is **Instagram**.\n",
        "*   For the type of post question there are two types the model takes:\n",
        " * IG reel  \n",
        " * IG image\n",
        "*   For the hour posted question, the model uses a 24 hour scale. For example:\n",
        " * 0 = 12 am\n",
        " * 23 = 11 pm\n",
        "*   For the month posted question, you type in the number that correlated to the month you want to post. For example:\n",
        " * 1 = January\n",
        " * 12 = December\n",
        "*   For the day of the week question, you will have to type in the number that corresponds to the day of the week you want to post.\n",
        " * 0 = Monday\n",
        " * 1 = Tuesday\n",
        " * 2 = Wednesday\n",
        " * 3 = Thursday\n",
        " * 4 = Friday\n",
        " * 5 = Saturday\n",
        " * 6 = Sunday\n",
        "\n",
        "* When entering a description/caption, you should be able to type in what you want. If you run into any isssues with your caption being too long please let me know.\n",
        "## Sample User input:\n",
        "\n",
        "*   What will be the duration of the post (in seconds)? If the post is an image, enter 0. **0**\n",
        "*   Which platform will the post be on? **Instagram**\n",
        "*   What type of post will it be? IG reel or IG image? **IG reel**\n",
        "*   What hour of the day will the post be published (0-23)? **18**\n",
        "*   What month will the post be published (1-12)? **7**\n",
        "*   What day of the week will the post be published (0 for Monday, 6 for Sunday)? **2**\n",
        "*   Please provide a caption / description for the post: **Next week will be villains!!! #movies #movie #superheroes #fyp #viral #trendy #cooledtured #marvelstudios #humor #funny #comedy**\n",
        "\n",
        "## Sample Output:\n",
        "*   Estimated Likes: **9.18**\n",
        "\n",
        "*   Rounded Likes:  **9.00**\n",
        "\n",
        "*   Do you want to make another prediction? (yes/no): **no**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xKnTT5-LaQw7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4285d86-edbd-457f-b7f1-d3107f57ee48",
        "id": "wORYkwbCSmEL"
      },
      "source": [
        "import scipy\n",
        "import numpy as np\n",
        "\n",
        "def predict_likes(model, encoder, tfidf, numerical_feature_names_to_collect, all_numerical_feature_names, categorical_feature_names, numerical_means):\n",
        "\n",
        "    user_input = {}\n",
        "    print(\"Please answer the following questions:\")\n",
        "\n",
        "    # Get specified numerical feature input\n",
        "    for feature in numerical_feature_names_to_collect:\n",
        "        while True:\n",
        "            try:\n",
        "                # Changed prompt to a question\n",
        "                if feature == \"Duration (sec)\":\n",
        "                    value = float(input(f\"What will be the duration of the post (in seconds)? If the post is an image, enter 0. \"))\n",
        "                else:\n",
        "                     value = float(input(f\"What is the value for {feature}? \"))\n",
        "                user_input[feature] = value\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a numerical value.\")\n",
        "\n",
        "    # Get categorical feature input\n",
        "    for feature in categorical_feature_names:\n",
        "        if feature == \"Platform\":\n",
        "            user_input[feature] = input(f\"Which platform will the post be on? \")\n",
        "        elif feature == \"Post type\":\n",
        "            user_input[feature] = input(f\"What type of post will it be? IG reel or IG image? \")\n",
        "        elif feature == \"Hour\":\n",
        "             user_input[feature] = input(f\"What hour of the day will the post be published (0-23)? \")\n",
        "        elif feature == \"Month\":\n",
        "             user_input[feature] = input(f\"What month will the post be published (1-12)? \")\n",
        "        elif feature == \"Day_of_Week\":\n",
        "             user_input[feature] = input(f\"What day of the week will the post be published (0 for Monday, 6 for Sunday)? \")\n",
        "        else:\n",
        "            user_input[feature] = input(f\"What is the value for {feature}? \")\n",
        "\n",
        "\n",
        "    # Get Description input for text feature\n",
        "    user_input['Description'] = input(\"Please provide a caption / description for the post: \")\n",
        "\n",
        "\n",
        "    # Create a DataFrame from user input, including all numerical features\n",
        "    # Fill missing numerical features with their means from the training data\n",
        "    user_df = pd.DataFrame([user_input])\n",
        "    for feature in all_numerical_feature_names:\n",
        "        if feature not in user_df.columns:\n",
        "            user_df[feature] = numerical_means[feature]\n",
        "\n",
        "\n",
        "    # Process categorical features using the fitted encoder\n",
        "    user_categorical_features = encoder.transform(user_df[categorical_feature_names])\n",
        "\n",
        "    # Process text feature using the fitted TF-IDF vectorizer\n",
        "    user_tfidf_matrix = tfidf.transform(user_df['Description'])\n",
        "\n",
        "    # Combine all features\n",
        "    # Ensure the order of numerical features matches the training data\n",
        "    user_numerical_features_sparse = scipy.sparse.csr_matrix(user_df[all_numerical_feature_names].values)\n",
        "    user_features = scipy.sparse.hstack((user_numerical_features_sparse, user_categorical_features), format='csr')\n",
        "    user_features_with_text = scipy.sparse.hstack((user_features, user_tfidf_matrix), format='csr')\n",
        "\n",
        "\n",
        "    # Predict using the model\n",
        "    predicted_likes = model.predict(user_features_with_text)\n",
        "\n",
        "    return predicted_likes[0] # Return the single prediction\n",
        "\n",
        "# Define the lists of feature names used during training and the ones to collect from the user\n",
        "all_numerical_feature_names = [\"Duration (sec)\",\"Reach\", \"Shares\", \"Plays\", \"Comments\", \"Saves\"] # Corrected to match the features used in training\n",
        "numerical_feature_names_to_collect = [\"Duration (sec)\"] # Only collect Duration (sec) from user\n",
        "#categorical_feature_names_for_prediction = [\"Platform\", \"Post type\", \"Genres\", \"Content_type\", \"Hour\", \"Month\", \"Day_of_Week\"] # with genre and content type\n",
        "categorical_feature_names_for_prediction = [\"Platform\", \"Post type\",\"Hour\", \"Month\", \"Day_of_Week\"] # without genre and content type\n",
        "\n",
        "# Calculate the mean of numerical features from the training data\n",
        "numerical_means = df[all_numerical_feature_names].mean().to_dict()\n",
        "\n",
        "\n",
        "while True:\n",
        "    estimated_likes = predict_likes(\n",
        "        ridge_fit_with_text,\n",
        "        encoder,\n",
        "        tfidf,\n",
        "        numerical_feature_names_to_collect,\n",
        "        all_numerical_feature_names,\n",
        "        categorical_feature_names_for_prediction,\n",
        "        numerical_means\n",
        "    )\n",
        "    print(f\"\\nEstimated Likes: {estimated_likes:.2f}\")\n",
        "    print(f\"\\nRounded Likes:  {round(estimated_likes):.2f}\")\n",
        "\n",
        "    another_prediction = input(f\"\\nDo you want to make another prediction? (yes/no): \").lower()\n",
        "    if another_prediction != 'yes':\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please answer the following questions:\n",
            "What will be the duration of the post (in seconds)? If the post is an image, enter 0. 0\n",
            "Which platform will the post be on? Instagram\n",
            "What type of post will it be? IG reel or IG image? IG reel\n",
            "What hour of the day will the post be published (0-23)? 0\n",
            "What month will the post be published (1-12)? 1\n",
            "What day of the week will the post be published (0 for Monday, 6 for Sunday)? 2\n",
            "Please provide a caption / description for the post: \"Who would you pick to invite in New Year's Eve? Are you Team Tifa or Team Aerith?  Happy New Year 2022 from all of us here at cooledtured! We hope you had an amazing 2021! We sure did, thanks to all of your support over the past year. Here’s to an equally great 2022!  #FinalFantasy7 #FF7 #Tifa #Aerith #NewYear2022 #HappyNewYear #toyshop #actionfigure #toysofinstagram #toysnearme\"\n",
            "\n",
            "Estimated Likes: 13.17\n",
            "\n",
            "Rounded Likes:  13.00\n",
            "\n",
            "Do you want to make another prediction? (yes/no): no\n"
          ]
        }
      ]
    }
  ]
}